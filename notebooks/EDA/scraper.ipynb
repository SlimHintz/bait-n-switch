{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/tjh/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import string\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "# Custom modules \n",
    "from modules import preprocessing as pp\n",
    "from modules import graph\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "# Extend stopwords (see analysis below)\n",
    "extension = {\n",
    "    'trumps',\n",
    "    'trump',\n",
    "    'obama',\n",
    "    'donald',\n",
    "    'new',\n",
    "    'u',\n",
    "    'tramp'\n",
    "}\n",
    "stop_words.update(extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first function just has to access a url and return a list of all headlines\n",
    "url = 'https://twitter.com/home'\n",
    "response = requests.get(url)\n",
    "\n",
    "def get_headlines(response_text, tags=['h1', 'h2', 'h3', 'h4']):\n",
    "    soup = BeautifulSoup(response_text, 'lxml')\n",
    "    headers = soup.find_all(tags)\n",
    "    return [header.text for header in headers]\n",
    "\n",
    "def clean_headlines(title, length):\n",
    "#     if len(title.split()) >= length:\n",
    "#         return None\n",
    "#     else:\n",
    "        # strip newline characters\n",
    "    title = title.replace(\"\\n\", \"\")\n",
    "    title = title.replace(\"\\t\", \"\")\n",
    "    title = pp.remove_non_ascii_chars(title)\n",
    "    title = pp.lower_case(title)\n",
    "    title = pp.remove_contractions(title)\n",
    "    title = pp.lemmetise_series(title)\n",
    "    title = \"\".join([char for char in title if char not in string.punctuation])\n",
    "    # remove stopwords\n",
    "    title = \" \".join([char for char in tokenizer.tokenize(title) if char not in stop_words ])\n",
    "    if len(title.split()) < length:\n",
    "         return None\n",
    "\n",
    "    return title\n",
    "# Convert to ascii\n",
    "# lower case \n",
    "# remove everything that is not printable.\n",
    "    \n",
    "def get_cleaned_headlines(url, length=3, tags=['h1', 'h2', 'h3']):\n",
    "    text = requests.get(url).text\n",
    "    return [clean_headlines(headline, length) for headline in get_headlines(text, tags=tags)]\n",
    "\n",
    "def convert_list_to_X(cleaned_headlines, pipeline):\n",
    "    # Convert list to a pandas sereios\n",
    "    series = pd.Series(cleaned_headlines, name='title')\n",
    "    X = pipeline.fit(X)\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.Series(clean_headlines('clickbait is cancer', 2), name='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                            wednesday evening briefing\n",
       "1                                  listen american life\n",
       "2                                   modern love podcast\n",
       "3     staring deadline congress nears 900 billion st...\n",
       "4     hospital discover surprise vaccine deliveries ...\n",
       "6     pandemic yet official stress us vaccination begin\n",
       "7     vaccination campaign nursing home face obstacl...\n",
       "8                  effective mask wearing may know soon\n",
       "9     health worker alaska serious allergic reaction...\n",
       "11                            case per caput arehighest\n",
       "12                                          us hot spot\n",
       "15                           trackerschoose place track\n",
       "17                                          us hot spot\n",
       "22                                          us hot spot\n",
       "27    billion spent us defense failed detect giant r...\n",
       "28           bidens inaugural mostly virtual money real\n",
       "29    biden introduces buttigieg pick lead transport...\n",
       "30    president elect joe biden expected name brenda...\n",
       "31    noreaster updates snowfall total could reach t...\n",
       "32    wa stunned big gift small college unexpected s...\n",
       "33    china brings moon rock earth era competition s...\n",
       "34               putting mask raised naomi osakas voice\n",
       "36    people thought covid 19 wa relatively harmless...\n",
       "37                         many network russian control\n",
       "38                                    move never forget\n",
       "40                       would known mom gone menopause\n",
       "41                        took mitch mcconnell six week\n",
       "42                               make think 2021 better\n",
       "43                mitch mcconnells motive self interest\n",
       "44    magic number reducing infection keeping busine...\n",
       "45               50 pound bag flour gone sanity remains\n",
       "46              asian american coalition teach democrat\n",
       "48                asked doe oreo keep releasing flavors\n",
       "49    cookie monster mural puzzle artist enrages pro...\n",
       "50                                  200000 sushi dinner\n",
       "53                          site information navigation\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.nytimes.com/'\n",
    "cleaned_headlines = pd.Series(pp.get_cleaned_headlines(url), name='title')\n",
    "series = cleaned_headlines.dropna()\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./../../src/models/model1.1.pickle', 'rb')\n",
    "clf = pickle.load(f)\n",
    "f = open('./../../src/models/tfidf1.1.pickle', 'rb')\n",
    "tfidf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.Series(pp.clean_headlines('There’s A Sound That Apparently Only Teenagers Can Hear. Can You Hear It?', 2), name='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = test\n",
    "\n",
    "X_tfidf = tfidf.transform(X)\n",
    "predictions = clf.predict(X_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.sum()/predictions.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wednesday evening briefing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        title  target\n",
       "0  wednesday evening briefing       0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = pd.Series(predictions, name='target')\n",
    "\n",
    "df = pd.DataFrame(list((zip(series, target))), columns=['title', 'target'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'timothee chalamets snl impression harry style weird thing'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_headlines(\"Timothée Chalamet’s “SNL” Impression Of Harry Styles Is Doing Weird Things To Me\", length=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This browser is no longer supported.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_headlines(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'things from amazon that will make perfect gifts'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.remove_contractions(pp.lower_case(pp.remove_non_ascii_chars('Things From Amazon That’ll Make Perfect Gifts')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_headlines(response_text):\n",
    "    soup = BeautifulSoup(response_text, 'lxml')\n",
    "    headlines = soup.find_all(attrs={\"itemprop\": \"headline\"})\n",
    "    for headline in headlines:\n",
    "        print(headline.text)\n",
    "        \n",
    "def print_text(response_text):\n",
    "    soup = BeautifulSoup(response_text, 'lxml')\n",
    "    text = soup.find_all(\"h1\")\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.cnn.com/2020/12/13/health/us-coronavirus-sunday/index.html'\n",
    "response = requests.get(url)\n",
    "print_headlines(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h1 class=\"pg-headline\">Covid-19 vaccine en route to every state as health officials say they hope immunizations begin Monday</h1>]\n"
     ]
    }
   ],
   "source": [
    "print_text(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/tjh/Flatiron/capstone/bait-n-switch/notebooks/EDA/buffer.html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32mbuffer.html\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0m__file__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'buffer.html'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'buffer.html'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/tjh/Flatiron/capstone/bait-n-switch/notebooks/EDA/buffer.html'"
     ]
    }
   ],
   "source": [
    "def replace(string, replacement_message, html):\n",
    "    response = requests.get(html)\n",
    "    soup = BeautifulSoup(response.text)\n",
    "    nodes_to_censor = soup.findAll(text=re.compile(string))\n",
    "    for node in nodes_to_censor:\n",
    "        node.replaceWith(replacement_message)\n",
    "        print(node)\n",
    "\n",
    "__file__ = 'buffer.html'\n",
    "base = os.path.dirname(os.path.abspath(__file__))\n",
    "html = open(os.path.join(base, 'buffer.html'))\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "for i in soup.find('div', {\"id\":None}).findChildren():\n",
    "    i.replace_with('##')\n",
    "\n",
    "with open(\"example_modified.html\", \"wb\") as f_output:\n",
    "    f_output.write(soup.prettify(\"utf-8\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = 'buffer.html'\n",
    "base = os.path.dirname(os.path.abspath(__file__))\n",
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.abspath('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
