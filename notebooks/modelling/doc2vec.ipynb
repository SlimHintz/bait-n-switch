{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "# Custom modules \n",
    "from modules import preprocessing as pp\n",
    "from modules import graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "def cleanText(text):\n",
    "    text = BeautifulSoup(text, \"lxml\").text\n",
    "    text = re.sub(r'\\|\\|\\|', r' ', text) \n",
    "    text = re.sub(r'http\\S+', r'<URL>', text)\n",
    "    text = text.lower()\n",
    "    text = text.replace('x', '')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>dataset</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bill Changing Credit Card Rules Is Sent to Oba...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In Hollywood, the Easy-Money Generation Toughe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1700 runners still unaccounted for in UK's Lak...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  dataset  target\n",
       "0  Bill Changing Credit Card Rules Is Sent to Oba...        1       0\n",
       "1  In Hollywood, the Easy-Money Generation Toughe...        1       0\n",
       "2  1700 runners still unaccounted for in UK's Lak...        1       0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import datat\n",
    "df = pd.read_csv(\"../../src/data/df_one_plus_three.csv\")\n",
    "\n",
    "#inspect the first few rows\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df['title'].apply(cleanText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.title = df.title.apply(pp.remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.title = df.title.apply(pp.remove_contractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.3, random_state=42)\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word.lower())\n",
    "    return tokens\n",
    "\n",
    "\n",
    "train_tagged = train.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['title']), tags=[r.target]), axis=1)\n",
    "test_tagged = test.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['title']), tags=[r.target]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36076/36076 [00:00<00:00, 1047131.97it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36076/36076 [00:00<00:00, 942600.11it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1860056.19it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1970051.05it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 2000895.38it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1792965.19it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 2072506.66it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 2127493.37it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1933647.41it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 2075633.90it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 2000551.47it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 2078199.58it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1902862.35it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1188153.39it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 2105908.13it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 2010252.44it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 2088554.86it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1902958.07it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 2110608.03it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 2099538.10it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 2117638.08it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1925821.37it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 2017327.86it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 2090285.97it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1942185.26it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1981323.96it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1971591.22it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1835373.67it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 2046300.78it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 2133402.58it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1943757.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 7s, sys: 10.1 s, total: 1min 17s\n",
      "Wall time: 1min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors\n",
    "\n",
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.7122623205277454\n",
      "Testing F1 score: 0.7103591986198382\n"
     ]
    }
   ],
   "source": [
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)\n",
    "logreg = BernoulliNB(alpha=0.01)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36076/36076 [00:00<00:00, 1102628.51it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dmm = Doc2Vec(dm=1, dm_mean=1, vector_size=300, window=10, negative=5, min_count=1, workers=5, alpha=0.065, min_alpha=0.065)\n",
    "model_dmm.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36076/36076 [00:00<00:00, 1595866.85it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1108192.49it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1693626.93it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1783728.76it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1863148.12it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1541909.14it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 2076061.07it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1708794.03it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1742382.36it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1758521.15it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1940815.13it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1080534.37it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1271041.78it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1904562.87it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1749918.60it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1059493.70it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1716333.88it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1773235.26it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1515470.94it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1722586.39it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1191212.05it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1891870.71it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1151042.24it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1185073.28it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1933425.05it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1589747.02it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1861406.21it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1876596.28it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1699447.55it/s]\n",
      "100%|██████████| 36076/36076 [00:00<00:00, 1713670.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 3s, sys: 14 s, total: 2min 17s\n",
      "Wall time: 2min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_dmm.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dmm.alpha -= 0.002\n",
    "    model_dmm.min_alpha = model_dmm.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.42387789419221317\n",
      "Testing F1 score: 0.31118262999365315\n"
     ]
    }
   ],
   "source": [
    "y_train, X_train = vec_for_learning(model_dmm, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dmm, test_tagged)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dbow.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "model_dmm.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "new_model = ConcatenatedDoc2Vec([model_dbow, model_dmm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.4411460354417281\n",
      "Testing F1 score: 0.33472492448619645\n"
     ]
    }
   ],
   "source": [
    "y_train, X_train = get_vectors(new_model, train_tagged)\n",
    "y_test, X_test = get_vectors(new_model, test_tagged)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a validation dataset:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe is the combination of both `dataset 1` and `dataset 3` outlined in the README and created in `./notebooks/EDA/datasetCreation`. Currently, with minimal preprocessing and a simple Naive Bayes Classifier I was able to achieve an accuracy of 0.88 and an f1 of 0.87. My goal here is to improve that score by implementing some data cleaning steps prior to tokenization. Then, once I am convinced that my data prep steps are working, I will move onto implementing word imbeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non_ascii characters\n",
    "df['title_cleaned'] = df.title.apply(pp.remove_non_ascii_chars)\n",
    "# Lowercase the words\n",
    "df.title_cleaned = df.title_cleaned.apply(pp.lower_case)\n",
    "# Remove contractions\n",
    "df.title_cleaned = df.title_cleaned.apply(pp.remove_contractions)\n",
    "# Remove stopwords\n",
    "df.title_cleaned = df.title_cleaned.apply(remove_stopwords)\n",
    "# Remove spelling mistakes \n",
    "df.title_cleaned = df.title_cleaned.apply(pp.fix_spelling_mistakes)\n",
    "\n",
    "# Remove all punctuation\n",
    "df.title_cleaned = df.title_cleaned.apply(pp.remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('spellcorrected.pickle', 'wb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    pickle.dump(df, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_cleaned = graph.get_vocab_length(df.title_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_dict= graph.get_vocab_length(df.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords \n",
    "df.title_cleaned = df.title_cleaned.apply(pp.remove_stopwords)\n",
    "df.title_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(title):\n",
    "    return \" \".join([word.lower() for word in tokenizer.tokenize(title) if word.lower() not in stop_words])\n",
    "df.title_cleaned = df.title_cleaned.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_cleaned = graph.get_vocab_length(df.title_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_cleaned_lem'] = df.title_cleaned.apply(pp.lemmetise_series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_cleaned_lem = graph.get_vocab_length(df.title_cleaned_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.show_wordcloud(title_cleaned_lem, title=\"Lemmetised Word Cloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.show_wordcloud(title_cleaned, title=\"Non Lemmetised Word Cloud\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like Lemmetiser will reduce \"US\" down to u. Which for our purposes is absolutely fine. we reduced the number of words in our corpus from 42k down to 31k. I think that we are now in a position to train test split and run a simple model on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.title_cleaned\n",
    "y = df.target\n",
    "X_train_lem, X_test_lem, y_train, y_test = train_test_split(X, y,\n",
    "                                                            random_state=42, test_size=0.2,\n",
    "                                                            stratify = df[['target', 'dataset']])\n",
    "\n",
    "X_train_lem.shape, X_test_lem.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=stop_words, ngram_range=(1,2))\n",
    "X_train_lem_tfidf = tfidf.fit_transform(X_train_lem)\n",
    "X_test_lem_tfidf = tfidf.transform(X_test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_clf = BernoulliNB(alpha = 0.4)\n",
    "\n",
    "bayes_clf.fit(X_train_lem_tfidf, y_train)\n",
    "y_hat_lem_train = bayes_clf.predict(X_train_lem_tfidf)\n",
    "y_hat_lem_test = bayes_clf.predict(X_test_lem_tfidf)\n",
    "\n",
    "accuracy_score(y_train, y_hat_lem_train), accuracy_score(y_test, y_hat_lem_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ok, so spell checking everyword is probably not worth it. What if we do doc2vec?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
